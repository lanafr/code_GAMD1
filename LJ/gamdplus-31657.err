2024-01-16 10:52:07.840257: I external/xla/xla/service/service.cc:168] XLA service 0x7629330 initialized for platform Interpreter (this does not guarantee that XLA will be used). Devices:
2024-01-16 10:52:07.840400: I external/xla/xla/service/service.cc:176]   StreamExecutor device (0): Interpreter, <undefined>
2024-01-16 10:52:07.870773: I external/xla/xla/pjrt/tfrt_cpu_pjrt_client.cc:218] TfrtCpuClient created.
2024-01-16 10:52:08.532439: I external/xla/xla/service/service.cc:168] XLA service 0x73dd490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-01-16 10:52:08.532477: I external/xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
2024-01-16 10:52:08.532840: I external/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc:198] Using BFC allocator.
2024-01-16 10:52:08.532894: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:105] XLA backend allocating 35730898944 bytes on device 0 for BFCAllocator.
2024-01-16 10:52:21.664653: I external/xla/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8500
2024-01-16 10:52:22.028287: I external/xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:52] Using nvlink for parallel linking
wandb: Currently logged in as: lana4655 (literallythehardestprojectever). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /home/guests/lana_frkin/GAMDplus/code/LJ/wandb/run-20240116_105245-5n8qgzzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Sequential model
wandb: ⭐️ View project at https://wandb.ai/literallythehardestprojectever/NeuralODE%20jej
wandb: 🚀 View run at https://wandb.ai/literallythehardestprojectever/NeuralODE%20jej/runs/5n8qgzzq
GPU available: True, used: False
TPU available: False, using: 0 TPU cores
Set SLURM handle signals.

  | Name  | Type     | Params
-----------------------------------
0 | model | ODEBlock | 1.6 M 
-----------------------------------
1.6 M     Trainable params
0         Non-trainable params
1.6 M     Total params
6.439     Total estimated model params size (MB)
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
WARNING:absl:Using a deprecated code path to create / update neighbor lists. It will be removed in a later version of JAX MD. Using `neighbor_fn.allocate` and `neighbor_fn.update` is preferred.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:    trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▁▇▇█▁█
wandb:          training loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         val loss_epoch █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  val loss_step/epoch_0 ▁
wandb:  val loss_step/epoch_1 ▁
wandb: val loss_step/epoch_10 ▁
wandb: val loss_step/epoch_11 ▁
wandb: val loss_step/epoch_12 ▁
wandb: val loss_step/epoch_13 ▁
wandb: val loss_step/epoch_14 ▁
wandb: val loss_step/epoch_15 ▁
wandb: val loss_step/epoch_16 ▁
wandb: val loss_step/epoch_17 ▁
wandb: val loss_step/epoch_18 ▁
wandb: val loss_step/epoch_19 ▁
wandb:  val loss_step/epoch_2 ▁
wandb: val loss_step/epoch_20 ▁
wandb: val loss_step/epoch_21 ▁
wandb: val loss_step/epoch_22 ▁
wandb: val loss_step/epoch_23 ▁
wandb: val loss_step/epoch_24 ▁
wandb: val loss_step/epoch_25 ▁
wandb: val loss_step/epoch_26 ▁
wandb: val loss_step/epoch_27 ▁
wandb: val loss_step/epoch_28 ▁
wandb: val loss_step/epoch_29 ▁
wandb:  val loss_step/epoch_3 ▁
wandb: val loss_step/epoch_30 ▁
wandb: val loss_step/epoch_31 ▁
wandb: val loss_step/epoch_32 ▁
wandb: val loss_step/epoch_33 ▁
wandb: val loss_step/epoch_34 ▁
wandb: val loss_step/epoch_35 ▁
wandb: val loss_step/epoch_36 ▁
wandb: val loss_step/epoch_37 ▁
wandb: val loss_step/epoch_38 ▁
wandb: val loss_step/epoch_39 ▁
wandb:  val loss_step/epoch_4 ▁
wandb:  val loss_step/epoch_5 ▁
wandb:  val loss_step/epoch_6 ▁
wandb:  val loss_step/epoch_7 ▁
wandb:  val loss_step/epoch_8 ▁
wandb:  val loss_step/epoch_9 ▁
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb:    trainer/global_step 359
wandb:          training loss 0.49556
wandb:         val loss_epoch 0.57492
wandb:  val loss_step/epoch_0 860.58746
wandb:  val loss_step/epoch_1 216.2471
wandb: val loss_step/epoch_10 0.59135
wandb: val loss_step/epoch_11 0.5949
wandb: val loss_step/epoch_12 0.57953
wandb: val loss_step/epoch_13 0.57666
wandb: val loss_step/epoch_14 0.58425
wandb: val loss_step/epoch_15 0.57705
wandb: val loss_step/epoch_16 0.5801
wandb: val loss_step/epoch_17 0.56955
wandb: val loss_step/epoch_18 0.57243
wandb: val loss_step/epoch_19 0.58326
wandb:  val loss_step/epoch_2 30.25593
wandb: val loss_step/epoch_20 0.57625
wandb: val loss_step/epoch_21 0.57005
wandb: val loss_step/epoch_22 0.57641
wandb: val loss_step/epoch_23 0.57032
wandb: val loss_step/epoch_24 0.57668
wandb: val loss_step/epoch_25 0.57915
wandb: val loss_step/epoch_26 0.57968
wandb: val loss_step/epoch_27 0.58067
wandb: val loss_step/epoch_28 0.59134
wandb: val loss_step/epoch_29 0.58048
wandb:  val loss_step/epoch_3 17.42488
wandb: val loss_step/epoch_30 0.5813
wandb: val loss_step/epoch_31 0.58024
wandb: val loss_step/epoch_32 0.58228
wandb: val loss_step/epoch_33 0.58126
wandb: val loss_step/epoch_34 0.56892
wandb: val loss_step/epoch_35 0.56801
wandb: val loss_step/epoch_36 0.58952
wandb: val loss_step/epoch_37 0.5687
wandb: val loss_step/epoch_38 0.57828
wandb: val loss_step/epoch_39 0.57492
wandb:  val loss_step/epoch_4 16.68371
wandb:  val loss_step/epoch_5 9.15071
wandb:  val loss_step/epoch_6 3.77099
wandb:  val loss_step/epoch_7 1.51428
wandb:  val loss_step/epoch_8 0.81773
wandb:  val loss_step/epoch_9 0.60937
wandb: 
wandb: 🚀 View run Sequential model at: https://wandb.ai/literallythehardestprojectever/NeuralODE%20jej/runs/5n8qgzzq
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20240116_105245-5n8qgzzq/logs
2024-01-16 12:59:27.439220: I external/xla/xla/pjrt/tfrt_cpu_pjrt_client.cc:221] TfrtCpuClient destroyed.
